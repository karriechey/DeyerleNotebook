{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karriechey/DeyerleNotebook/blob/main/WiDS_Team7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UBKqh2coVRHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9adf3fb2-ecb0-486e-d114-e5ce8448a136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "c8od1cOiT1B2",
        "outputId": "be7a0182-515d-4619-ee7d-efc1aa4cf244"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/WiDs Team7/data/train/TRAINING_SOLUTIONS.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1a8cd21d2fbf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load training datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_solutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/WiDs Team7/data/train/TRAINING_SOLUTIONS.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_CATEGORICAL_METADATA.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_quantitative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_QUANTITATIVE_METADATA.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/WiDs Team7/data/train/TRAINING_SOLUTIONS.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training datasets\n",
        "train_solutions = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/train/TRAINING_SOLUTIONS.xlsx')\n",
        "train_categorical = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_CATEGORICAL_METADATA.xlsx')\n",
        "train_quantitative = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_QUANTITATIVE_METADATA.xlsx')\n",
        "train_fmri = pd.read_csv('/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "\n",
        "# Load test datasets\n",
        "test_categorical = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/test//TEST_CATEGORICAL.xlsx')\n",
        "test_quantitative = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/test/TEST_QUANTITATIVE_METADATA.xlsx')\n",
        "test_fmri = pd.read_csv('/content/drive/MyDrive/WiDs Team7/data/test/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "\n",
        "# Inspect the first few rows and get data types\n",
        "print(train_solutions.head())\n",
        "print(train_solutions.info())\n",
        "\n",
        "# Drop rows with missing values in any column\n",
        "train_solutions = train_solutions.dropna()\n",
        "\n",
        "# Fill missing values with the median, but only for numeric columns\n",
        "train_solutions_numeric = train_solutions.select_dtypes(include=['float64', 'int64'])\n",
        "train_solutions[train_solutions_numeric.columns] = train_solutions_numeric.fillna(train_solutions_numeric.median())\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "train_solutions = pd.get_dummies(train_solutions, columns=['column_name'])\n",
        "\n",
        "# Standardize numerical columns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_solutions['numerical_column'] = scaler.fit_transform(train_solutions[['numerical_column']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values in training data:\")\n",
        "print(train_solutions.isnull().sum())\n",
        "print(train_categorical.isnull().sum())\n",
        "print(train_quantitative.isnull().sum())\n",
        "print(train_fmri.isnull().sum())\n",
        "\n",
        "# Handle missing values\n",
        "train_solutions.fillna(train_solutions.mean(), inplace=True)\n",
        "train_categorical.fillna(train_categorical.mode().iloc[0], inplace=True)\n",
        "train_quantitative.fillna(train_quantitative.mean(), inplace=True)\n",
        "train_fmri.fillna(train_fmri.mean(), inplace=True)\n",
        "\n",
        "# Separate the numeric columns from the non-numeric ones\n",
        "numeric_columns = train_solutions.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Fill missing values for numeric columns with the mean of each column\n",
        "train_solutions[numeric_columns] = train_solutions[numeric_columns].fillna(train_solutions[numeric_columns].mean())\n",
        "\n",
        "# Fill non-numeric columns (e.g., categorical) with a placeholder 'Unknown'\n",
        "non_numeric_columns = train_solutions.select_dtypes(exclude=['number']).columns\n",
        "train_solutions[non_numeric_columns] = train_solutions[non_numeric_columns].fillna('Unknown')\n",
        "\n",
        "# One-hot encoding for categorical data\n",
        "categorical_cols = train_categorical.select_dtypes(include=['object']).columns\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')  # Avoid multicollinearity by dropping the first column\n",
        "train_categorical_encoded = encoder.fit_transform(train_categorical[categorical_cols])\n",
        "\n",
        "# Scaling quantitative data\n",
        "scaler = StandardScaler()\n",
        "train_quantitative_scaled = scaler.fit_transform(train_quantitative)\n",
        "\n",
        "# Combine processed data into a final DataFrame for training\n",
        "train_data = pd.concat([train_solutions, pd.DataFrame(train_categorical_encoded), pd.DataFrame(train_quantitative_scaled)], axis=1)\n",
        "\n",
        "# Display shapes and head of the data\n",
        "print(train_data.shape)\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "id": "iqgF5_zGUq8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f17180b8-b47b-4d32-84c9-4a7868608fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in training data:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_solutions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8315b0e359d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check for missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing values in training data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_solutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_quantitative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_solutions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = train.drop('target_column', axis=1)\n",
        "y = train['target_column']\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "RzZSmdD9Uv74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "108d86fc-787e-438f-9513-2e2df2d95e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ed0cf0bd3c15>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split data into features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target_column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_column'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Load training datasets\n",
        "train_solutions = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/train/TRAINING_SOLUTIONS.xlsx')\n",
        "train_categorical = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_CATEGORICAL_METADATA.xlsx')\n",
        "train_quantitative = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_QUANTITATIVE_METADATA.xlsx')\n",
        "train_fmri = pd.read_csv('/content/drive/MyDrive/WiDs Team7/data/train/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "\n",
        "# Load test datasets\n",
        "test_categorical = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/test//TEST_CATEGORICAL.xlsx')\n",
        "test_quantitative = pd.read_excel('/content/drive/MyDrive/WiDs Team7/data/test/TEST_QUANTITATIVE_METADATA.xlsx')\n",
        "test_fmri = pd.read_csv('/content/drive/MyDrive/WiDs Team7/data/test/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "\n",
        "# Ensure participant_id is unique in all datasets\n",
        "train_solutions = train_solutions.drop_duplicates(subset=['participant_id'])\n",
        "train_categorical = train_categorical.drop_duplicates(subset=['participant_id'])\n",
        "train_quantitative = train_quantitative.drop_duplicates(subset=['participant_id'])\n",
        "train_fmri = train_fmri.drop_duplicates(subset=['participant_id'])\n",
        "\n",
        "# Merge data with targets\n",
        "train_data = train_categorical.merge(train_quantitative, on='participant_id', how='inner')\n",
        "train_data = train_data.merge(train_fmri, on='participant_id', how='inner')\n",
        "train_data = train_data.merge(train_solutions, on='participant_id', how='inner')\n",
        "\n",
        "# Preprocessing: Handle missing values in numeric columns only\n",
        "numeric_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "train_data[numeric_cols] = train_data[numeric_cols].fillna(train_data[numeric_cols].median())\n",
        "\n",
        "# One-hot encode categorical variables (excluding participant_id)\n",
        "categorical_cols = train_categorical.select_dtypes(include=['object']).columns\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
        "encoded_categorical = encoder.fit_transform(train_categorical[categorical_cols])\n",
        "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "quantitative_scaled = scaler.fit_transform(train_quantitative.drop(columns=['participant_id']))\n",
        "\n",
        "# Combine processed data\n",
        "feature_names = list(encoded_feature_names) + list(train_quantitative.drop(columns=['participant_id']).columns) + list(train_fmri.drop(columns=['participant_id']).columns)\n",
        "X = np.hstack([encoded_categorical, quantitative_scaled, train_fmri.drop(columns=['participant_id']).values])\n",
        "y_adhd = train_data['ADHD_Outcome']\n",
        "y_sex = train_data['Sex_F']\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train_adhd, y_val_adhd = train_test_split(X, y_adhd, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train_sex, y_val_sex = train_test_split(X, y_sex, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model training (XGBoost for better performance)\n",
        "xgb_adhd = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_sex = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "xgb_adhd.fit(X_train, y_train_adhd)\n",
        "xgb_sex.fit(X_train, y_train_sex)\n",
        "\n",
        "# Predictions on validation set\n",
        "y_pred_adhd = xgb_adhd.predict(X_val)\n",
        "y_pred_sex = xgb_sex.predict(X_val)\n",
        "\n",
        "# Evaluate using weighted F1-score\n",
        "f1_adhd = f1_score(y_val_adhd, y_pred_adhd)\n",
        "f1_sex = f1_score(y_val_sex, y_pred_sex)\n",
        "average_f1 = (f1_adhd + f1_sex) / 2\n",
        "\n",
        "print(f\"F1 Score ADHD: {f1_adhd:.4f}\")\n",
        "print(f\"F1 Score Sex: {f1_sex:.4f}\")\n",
        "print(f\"Final Average F1 Score: {average_f1:.4f}\")\n",
        "\n",
        "# Now process the test data and generate predictions\n",
        "print(\"\\nGenerating predictions for test data...\")\n",
        "\n",
        "# Prepare test data in the same way as training data\n",
        "test_data = test_categorical.merge(test_quantitative, on='participant_id', how='inner')\n",
        "test_data = test_data.merge(test_fmri, on='participant_id', how='inner')\n",
        "\n",
        "# Handle missing values in numeric columns\n",
        "numeric_cols = test_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "test_data[numeric_cols] = test_data[numeric_cols].fillna(test_data[numeric_cols].median())\n",
        "\n",
        "# One-hot encode categorical variables using the same encoder\n",
        "categorical_cols = test_categorical.select_dtypes(include=['object']).columns\n",
        "encoded_test_categorical = encoder.transform(test_categorical[categorical_cols])\n",
        "\n",
        "# Scale numerical features using the same scaler\n",
        "test_quantitative_scaled = scaler.transform(test_quantitative.drop(columns=['participant_id']))\n",
        "\n",
        "# Combine processed test data\n",
        "X_test = np.hstack([\n",
        "    encoded_test_categorical,\n",
        "    test_quantitative_scaled,\n",
        "    test_fmri.drop(columns=['participant_id']).values\n",
        "])\n",
        "\n",
        "# Get participant IDs for the final submission\n",
        "participant_ids = test_data['participant_id'].values\n",
        "\n",
        "# Make predictions\n",
        "test_pred_adhd = xgb_adhd.predict(X_test)\n",
        "test_pred_sex = xgb_sex.predict(X_test)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'participant_id': participant_ids,\n",
        "    'ADHD_Outcome': test_pred_adhd.astype(int),\n",
        "    'Sex_F': test_pred_sex.astype(int)\n",
        "})\n",
        "\n",
        "# Save to CSV in the required format\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# To match the exact format shown in the sample\n",
        "with open('submission_exact_format.csv', 'w') as f:\n",
        "    f.write('participant_id\\n\\nADHD_Outcome\\nSex_F\\n')\n",
        "    for _, row in submission.iterrows():\n",
        "        f.write(f\"{row['participant_id']}\\n{int(row['ADHD_Outcome'])}\\n{int(row['Sex_F'])}\\n\")\n",
        "\n",
        "print(\"Submission files created!\")\n",
        "print(\"Preview of submission data:\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "id": "oWepOr-jDeDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16d7932-c650-4872-bc5d-bcbf606a6eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:57:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:59:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    }
  ]
}